{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/mikayil/ai4digigov-hackaton?scriptVersionId=88504023\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nnp.random.seed(420)\nimport pandas as pd\nimport matplotlib\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nimport optuna\nimport re\nfrom sklearn.utils import resample\n\nmatplotlib.rcParams['figure.figsize'] = [20, 10]\n\nDEV = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data stuff","metadata":{}},{"cell_type":"markdown","source":"## Loading","metadata":{}},{"cell_type":"code","source":"%%time\n\ntrain_df = pd.read_csv('queue_dataset_train.csv')\n\nif DEV:\n    train_df = train_df.sample(n=500000)\n    \ntrain_df = train_df.dropna()\ntrain_df = train_df.reset_index(drop=True)\n\ntest_df = pd.read_csv('queue_dataset_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic data stats","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data cleaning","metadata":{}},{"cell_type":"code","source":"def one_hot_encode(df, columns):\n    res = None\n    \n    for col in columns:\n        res_col = pd.get_dummies(df[col], prefix=col)\n        if not isinstance(res, pd.DataFrame):\n            res = res_col\n        else:\n            res = pd.concat([res, res_col], axis=1)\n    \n    res = pd.concat([res, df], axis=1)\n    \n    res = res.rename(lambda c: c[:40], axis=1)\n    \n    return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if DEV:\n#     train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disc_cols = ['branch_name', 'customer_gender', 'customer_city', 'service_name_organization', 'service_name', 'service_name_2']\n\ntrain_df = one_hot_encode(train_df, disc_cols)\ntest_df_clean = one_hot_encode(test_df, disc_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if DEV:\n#     train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def heatmap(df):\n    corr = df.corr()\n    \n    sns.heatmap(corr, cmap='RdYlGn', linewidths=0.2)\n    \n    fig = plt.gcf()\n    plt.show()\n    \n    return corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# if DEV:\n#     corr = heatmap(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if DEV:\n#     sorted_ids = np.argsort(np.abs(corr['service_canceled']))\n#     sorted_ids.sort_values()[-10:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clean age","metadata":{}},{"cell_type":"code","source":"def fix_ages(ages_raw, mean=None, std=None):\n    ages = []\n    \n    for row in tqdm(ages_raw):\n        if isinstance(row, str):\n            age = np.sum(list(map(int, row.split('-')))) / 2\n        else:\n            age = row\n            \n        if np.isnan(age):\n            age = mean if mean != None else 30\n            \n        ages.append(age)\n    \n    ages = np.array(ages)\n    \n    print(ages)\n    \n    if mean == None:\n        mean = np.mean(ages)\n        \n    if std == None:\n        std = np.std(ages)\n        \n    print(f\"mean: {mean}, std: {std}\")\n        \n    res = []\n        \n    for age in tqdm(ages):\n        res.append((age - mean) / std)\n    \n    return res, mean, std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['customer_age_appl'], mean, std = fix_ages(train_df['customer_age_appl'])\ntest_df_clean['customer_age_appl'], mean, std = fix_ages(test_df_clean['customer_age_appl'], mean, std)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if DEV:\n#     corr = heatmap(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clean time","metadata":{}},{"cell_type":"code","source":"def fix_time(times_raw):\n    times = []\n    \n    for t in tqdm(times_raw):\n        if not isinstance(t, str) and np.isnan(t):\n            t = \"12:00:00.0\"\n            \n        ts = t.split(\":\")\n        hours = int(ts[0])\n        minutes = int(ts[1])\n        seconds = int(ts[2].split('.')[0])\n        \n        times.append(hours * 3600 + minutes * 60 + seconds)\n    \n    return np.array(times) / 86400","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['time_start_process'] = fix_time(train_df['time_start_process'])\ntest_df_clean['time_start_process'] = fix_time(test_df_clean['time_start_process'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if DEV:\n#     corr = heatmap(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_add = []\n\nfor col in test_df_clean.columns:\n    if not col in train_df.columns:\n        cols_to_add.append(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, pd.DataFrame({col: np.zeros(len(train_df)) for col in cols_to_add})], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clean date","metadata":{}},{"cell_type":"code","source":"def fix_date(df):\n    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n\n    df['weekday'] = [x.weekday() for x in df.date]\n    df['day'] = [x.day for x in df.date]\n    df['year'] = [x.year for x in df.date]\n    df['month'] = [x.month for x in df.date]\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = fix_date(train_df)\ntest_df_clean = fix_date(test_df_clean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = one_hot_encode(train_df, ['weekday'])\ntest_df_clean = one_hot_encode(test_df_clean, ['weekday'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Organization name + service name + service name 2 ","metadata":{}},{"cell_type":"code","source":"def get_column_coefs(df, column):\n    res = {}\n    \n    uniques = df[column].unique()\n    \n    for val in uniques:\n        norm = len(df.loc[test_df[column] == val]) / len(df)\n        \n        res[val] = norm\n    \n    return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def service_popularity(df, service_name_organization_coefs=None, service_name_coefs=None, service_name_2_coefs=None):\n    if service_name_organization_coefs == None:\n        service_name_organization_coefs = get_column_coefs(test_df, 'service_name_organization')\n    df = df.replace({'service_name_organization': service_name_organization_coefs})\n\n    if service_name_coefs == None:\n        service_name_coefs = get_column_coefs(test_df, 'service_name')\n    df = df.replace({'service_name': service_name_coefs})\n\n    if service_name_2_coefs == None:\n        service_name_2_coefs = get_column_coefs(test_df, 'service_name_2')\n    df = df.replace({'service_name_2': service_name_2_coefs})\n\n    df['popularity_coeff'] = df.service_name * df.service_name_2 * df.service_name_organization\n    \n    return df, service_name_organization_coefs, service_name_coefs, service_name_2_coefs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, service_name_organization_norm, service_name_norm, service_name_2_norm = service_popularity(train_df)\ntest_df_clean, service_name_organization_norm, service_name_norm, service_name_2_norm = service_popularity(test_df_clean, service_name_organization_norm, service_name_norm, service_name_2_norm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"drop_cols = ['id', 'branch_name', 'customer_gender', 'customer_city', 'service_name_organization', 'service_name', 'service_name_2', 'date', 'weekday', 'day', 'month', 'year']\n\nseed = 420\n\ntrain_df_ = train_df.drop(['service_canceled'] + drop_cols, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_ = train_df_.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\ntrain_df = train_df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\nx_train, x_test, y_train, y_test = train_test_split(train_df_, train_df['service_canceled'],\n                                                    test_size=0.2,\n                                                    random_state=seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parameter Tuning with Optuna","metadata":{}},{"cell_type":"code","source":"def LightGBM(params, X_train_adv, X_valid_adv, y_train_adv, y_valid_adv):\n    # Set data\n    lgb_train = lgb.Dataset(X_train_adv, y_train_adv)\n    lgb_valid = lgb.Dataset(X_valid_adv, y_valid_adv, reference = lgb_train)\n    # Training\n    model = lgb.train(\n        params,\n        lgb_train,\n        valid_sets = [lgb_train, lgb_valid],\n        num_boost_round = 100,\n        early_stopping_rounds = 100\n    )\n    # Prediction\n    y_pred = model.predict(X_valid_adv, num_iteration = model.best_iteration)\n    # Evaluation\n    ROC_AUC_Score = roc_auc_score(y_valid_adv,y_pred)\n    print('ROC AUC Score of LightGBM =', ROC_AUC_Score)\n    return ROC_AUC_Score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'task': 'train',\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'seed': 420,\n        'metric': 'AUC',\n        'is_unbalance':True,\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 0.9),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 0.9),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n    }\n    \n    return LightGBM(params, x_train, x_test, y_train, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#from optuna.samplers import TPESampler\n#study = optuna.create_study(direction = 'maximize', sampler = TPESampler(seed=420))\n#study.optimize(objective, n_trials = 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'lambda_l1': 0.12316592750974795, 'lambda_l2': 0.8462662628054513, 'num_leaves': 171, \n          'feature_fraction': 0.5759943289441473, 'bagging_fraction': 0.703925954466332,\n          'bagging_freq': 5, 'min_child_samples': 25, 'learning_rate': 0.0965962567977748, \n         'task': 'train',\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'seed': 420,\n        'metric': 'AUC',\n        'is_unbalance':True,'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Install GPU**","metadata":{}},{"cell_type":"code","source":"%%time\n!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n!git clone --recursive https://github.com/Microsoft/LightGBM","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!apt-get install -y -qq libboost-all-dev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!cd LightGBM/python-package/;python3 setup.py install --precompile","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"%%time\n\n# model = get_model(study.best_params, 30)\n\nif len(drop_cols) > 0:\n    test_df_ = test_df_clean.drop(drop_cols, axis=1)\npreds = np.zeros(test_df_.shape[0])\nkf = StratifiedKFold(n_splits=10, shuffle=True)\nrmse=[]  # list contains rmse for each fold\nn=0\nfor trn_idx, test_idx in kf.split(train_df_, train_df['service_canceled']):\n    X_tr,X_val=train_df_.iloc[trn_idx],train_df_.iloc[test_idx]\n    y_tr,y_val=train_df['service_canceled'].iloc[trn_idx],train_df['service_canceled'].iloc[test_idx]\n    lgb_train = lgb.Dataset(X_tr, y_tr)\n    lgb_valid = lgb.Dataset(X_val, y_val, reference = lgb_train)\n    # Training\n    model3 = lgb.train(\n        params,\n        lgb_train,\n        valid_sets = [lgb_train, lgb_valid],\n        num_boost_round = 200,\n        early_stopping_rounds = 100\n    )\n    preds+= model3.predict(test_df_)/kf.n_splits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred_test = model2.predict_proba(test_df_)\n#y_scores_test = y_pred_test[:, 1]\n\n#test_df['service_canceled'] = preds\n#test_df[[\"id\", \"service_canceled\"]].to_csv(\"/kaggle/working/submission.csv\", index=False) == submission(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparative method","metadata":{}},{"cell_type":"code","source":"dfk = pd.DataFrame({ \n    'Kernel ID': ['A', 'B', 'C','D','E','F','G','H'],  \n    'Score': [0.72308,0.71875,0.72206,0.72289,0.72339,0.72342,0.72289,0.72316],\n    'File Path': ['../input/comparative/submission (7).csv',\n                  '../input/comparative/submission (6).csv',\n                  '../input/comparative2/submission (5).csv',\n                 '../input/comparative/submission (8).csv',\n                 '../input/comparative/submissionEnsenbled.csv',\n                 '../input/comparative/submissionEnsenbled2.csv',\n                  '../input/comparative/submission (9).csv',\n                 '../input/comparative/submission (10).csv']     \n})    \n    \ndfk = dfk.sort_values('Score')\ndfk.reset_index()\n\n\ndef generate(main, support, coeff):\n    \n    g = main.copy()    \n    for i in main.columns[1:]:\n        \n        res = []\n        lm, Is = [], []        \n        lm = main[i].tolist()\n        ls = support[i].tolist()  \n        \n        for j in range(len(main)):\n            res.append((lm[j] * coeff) + (ls[j] * (1.- coeff)))            \n        g[i] = res\n        \n    return g\n\nsupport = pd.read_csv(dfk.iloc[0, 2])\n\nfor k in range (1,8):\n    main = pd.read_csv(dfk.iloc[k, 2])\n    support = generate(main, support, 0.60)\n\nsub = support\n\n\nsub.to_csv(\"/kaggle/working/submissionEnsenbled5.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}